#include "common.h"

// mlt Header files
#include <framework/mlt_consumer.h>
#include <framework/mlt_frame.h>
#include <framework/mlt_profile.h>
#include <framework/mlt_log.h>
#include <framework/mlt_events.h>

// System header files
#include <stdio.h>
#include <stdlib.h>
#include <string.h>
#include <limits.h>
#include <pthread.h>
#include <sys/time.h>
#include <unistd.h>

// avformat header files
#include <libavformat/avformat.h>
#include <libavformat/avio.h>
#include <libswscale/swscale.h>
#include <libavutil/pixdesc.h>
#include <libavutil/mathematics.h>
#include <libavutil/samplefmt.h>
#include <libavutil/opt.h>
#include <libavutil/imgutils.h>
#include <libavutil/version.h>
#ifdef AVFILTER
#include <libavfilter/avfilter.h>
#include <libavfilter/buffersink.h>
#include <libavfilter/buffersrc.h>
#endif

#ifndef AV_CODEC_FLAG_GLOBAL_HEADER
#define AV_CODEC_FLAG_GLOBAL_HEADER  CODEC_FLAG_GLOBAL_HEADER
#define AV_CODEC_FLAG_QSCALE         CODEC_FLAG_QSCALE
#define AV_CODEC_FLAG_INTERLACED_DCT CODEC_FLAG_INTERLACED_DCT
#define AV_CODEC_FLAG_INTERLACED_ME  CODEC_FLAG_INTERLACED_ME
#define AV_CODEC_FLAG_PASS1          CODEC_FLAG_PASS1
#define AV_CODEC_FLAG_PASS2          CODEC_FLAG_PASS2
#endif

#define MAX_AUDIO_STREAMS (8)
#define AUDIO_ENCODE_BUFFER_SIZE (48000 * 2 * MAX_AUDIO_STREAMS)
#define AUDIO_BUFFER_SIZE (1024 * 42)
#define VIDEO_BUFFER_SIZE (8192 * 8192)
#define IMAGE_ALIGN (4)


#if defined(AVFILTER) && LIBAVUTIL_VERSION_MAJOR >= 56
static AVFilterGraph *vfilter_graph;


static AVBufferRef *hw_device_ctx;


#endif

// Forward references.
static void property_changed( mlt_properties owner, mlt_consumer self, char *name );
static int consumer_start( mlt_consumer consumer );
static int consumer_stop( mlt_consumer consumer );
static int consumer_is_stopped( mlt_consumer consumer );
static void *consumer_thread( void *arg );
static void consumer_close( mlt_consumer consumer );

/** Initialise the consumer.
*/

mlt_consumer consumer_avformat_init( mlt_profile profile, char *arg )
{
	// Allocate the consumer
	mlt_consumer consumer = mlt_consumer_new( profile );

	// If memory allocated and initialises without error
	if ( consumer != NULL )
	{
		// Get properties from the consumer
		mlt_properties properties = MLT_CONSUMER_PROPERTIES( consumer );

		// Assign close callback
		consumer->close = consumer_close;

		// Interpret the argument
		if ( arg != NULL )
			mlt_properties_set( properties, "target", arg );

		// sample and frame queue
		mlt_properties_set_data( properties, "frame_queue", mlt_deque_init( ), 0, ( mlt_destructor )mlt_deque_close, NULL );

		// Audio options not fully handled by AVOptions
#define QSCALE_NONE (-99999)
		mlt_properties_set_int( properties, "aq", QSCALE_NONE );
		
		// Video options not fully handled by AVOptions
		mlt_properties_set_int( properties, "dc", 8 );

		// Muxer options not fully handled by AVOptions
		mlt_properties_set_double( properties, "muxdelay", 0.7 );
		mlt_properties_set_double( properties, "muxpreload", 0.5 );

		// Ensure termination at end of the stream
		mlt_properties_set_int( properties, "terminate_on_pause", 1 );
		
		// Default to separate processing threads for producer and consumer with no frame dropping!
		mlt_properties_set_int( properties, "real_time", -1 );
		mlt_properties_set_int( properties, "prefill", 1 );

		// Set up start/stop/terminated callbacks
		consumer->start = consumer_start;
		consumer->stop = consumer_stop;
		consumer->is_stopped = consumer_is_stopped;
		
		mlt_events_register( properties, "consumer-fatal-error", NULL );
		mlt_event event = mlt_events_listen( properties, consumer, "property-changed", ( mlt_listener )property_changed );
		mlt_properties_set_data( properties, "property-changed event", event, 0, NULL, NULL );
	}

	// Return consumer
	return consumer;
}

static void recompute_aspect_ratio( mlt_properties properties )
{
	double ar = mlt_properties_get_double( properties, "aspect" );
	AVRational rational = av_d2q( ar, 255 );
	int width = mlt_properties_get_int( properties, "width" );
	int height = mlt_properties_get_int( properties, "height" );

	// Update the profile and properties as well since this is an alias
	// for mlt properties that correspond to profile settings
	mlt_properties_set_int( properties, "display_aspect_num", rational.num );
	mlt_properties_set_int( properties, "display_aspect_den", rational.den );

	// Now compute the sample aspect ratio
	rational = av_d2q( ar * height / FFMAX(width, 1), 255 );

	// Update the profile and properties as well since this is an alias
	// for mlt properties that correspond to profile settings
	mlt_properties_set_int( properties, "sample_aspect_num", rational.num );
	mlt_properties_set_int( properties, "sample_aspect_den", rational.den );
}

static void property_changed( mlt_properties owner, mlt_consumer self, char *name )
{
	mlt_properties properties = MLT_CONSUMER_PROPERTIES( self );

	if ( !strcmp( name, "s" ) )
	{
		// Obtain the size property
		char *size = mlt_properties_get( properties, "s" );
		int width = mlt_properties_get_int( properties, "width" );
		int height = mlt_properties_get_int( properties, "height" );
		int tw, th;

		if ( sscanf( size, "%dx%d", &tw, &th ) == 2 && tw > 0 && th > 0 )
		{
			width = tw;
			height = th;
		}
		else
		{
			mlt_log_warning( MLT_CONSUMER_SERVICE(self), "Invalid size property %s - ignoring.\n", size );
		}

		// Now ensure we honour the multiple of two requested by libavformat
		width = ( width / 2 ) * 2;
		height = ( height / 2 ) * 2;
		mlt_properties_set_int( properties, "width", width );
		mlt_properties_set_int( properties, "height", height );
		recompute_aspect_ratio( properties );
	}
	// "-aspect" on ffmpeg command line is display aspect ratio
	else if ( !strcmp( name, "aspect" ) || !strcmp( name, "width" ) || !strcmp( name, "height" ) )
	{
		recompute_aspect_ratio( properties );
	}
	// Handle the ffmpeg command line "-r" property for frame rate
	else if ( !strcmp( name, "r" ) )
	{
		double frame_rate = mlt_properties_get_double( properties, "r" );
		AVRational rational = av_d2q( frame_rate, 255 );
		mlt_properties_set_int( properties, "frame_rate_num", rational.num );
		mlt_properties_set_int( properties, "frame_rate_den", rational.den );
	}
    // Apply AVOptions that are synonyms for standard mlt_consumer options
    else if ( !strcmp( name, "ac" ) )
    {
        mlt_properties_set_int( properties, "channels", mlt_properties_get_int( properties, "ac" ) );
    }
    else if ( !strcmp( name, "ar" ))
    {
        mlt_properties_set_int( properties, "frequency", mlt_properties_get_int( properties, "ar" ) );
    }

}

/** Start the consumer.
*/

static int consumer_start( mlt_consumer consumer )
{
	// Get the properties
	mlt_properties properties = MLT_CONSUMER_PROPERTIES( consumer );
	int error = 0;

	// Report information about available muxers and codecs as YAML Tiny
	char *s = mlt_properties_get( properties, "f" );
	if ( s && strcmp( s, "list" ) == 0 )
	{
		mlt_properties doc = mlt_properties_new();
		mlt_properties formats = mlt_properties_new();
		char key[20];
		AVOutputFormat *format = NULL;
		
		mlt_properties_set_data( properties, "f", formats, 0, (mlt_destructor) mlt_properties_close, NULL );
		mlt_properties_set_data( doc, "formats", formats, 0, NULL, NULL );
		while ( ( format = av_oformat_next( format ) ) )
		{
			snprintf( key, sizeof(key), "%d", mlt_properties_count( formats ) );
			mlt_properties_set( formats, key, format->name );
		}
		s = mlt_properties_serialise_yaml( doc );
		fprintf( stdout, "%s", s );
		free( s );
		mlt_properties_close( doc );
		error = 1;
	}
	s = mlt_properties_get( properties, "acodec" );
	if ( s && strcmp( s, "list" ) == 0 )
	{
		mlt_properties doc = mlt_properties_new();
		mlt_properties codecs = mlt_properties_new();
		char key[20];
		AVCodec *codec = NULL;

		mlt_properties_set_data( properties, "acodec", codecs, 0, (mlt_destructor) mlt_properties_close, NULL );
		mlt_properties_set_data( doc, "audio_codecs", codecs, 0, NULL, NULL );
		while ( ( codec = av_codec_next( codec ) ) )
#if LIBAVCODEC_VERSION_INT >= ((57<<16)+(37<<8)+0)
			if ( (codec->encode2 || codec->send_frame) && codec->type == AVMEDIA_TYPE_AUDIO )
#else
			if ( codec->encode2 && codec->type == AVMEDIA_TYPE_AUDIO )
#endif
			{
				snprintf( key, sizeof(key), "%d", mlt_properties_count( codecs ) );
				mlt_properties_set( codecs, key, codec->name );
			}
		s = mlt_properties_serialise_yaml( doc );
		fprintf( stdout, "%s", s );
		free( s );
		mlt_properties_close( doc );
		error = 1;
	}
	s = mlt_properties_get( properties, "vcodec" );
	if ( s && strcmp( s, "list" ) == 0 )
	{
		mlt_properties doc = mlt_properties_new();
		mlt_properties codecs = mlt_properties_new();
		char key[20];
		AVCodec *codec = NULL;

		mlt_properties_set_data( properties, "vcodec", codecs, 0, (mlt_destructor) mlt_properties_close, NULL );
		mlt_properties_set_data( doc, "video_codecs", codecs, 0, NULL, NULL );
		while ( ( codec = av_codec_next( codec ) ) )
#if LIBAVCODEC_VERSION_INT >= ((57<<16)+(37<<8)+0)
			if ( (codec->encode2 || codec->send_frame) && codec->type == AVMEDIA_TYPE_VIDEO )
#else
			if ( codec->encode2 && codec->type == AVMEDIA_TYPE_VIDEO )
#endif
			{
				snprintf( key, sizeof(key), "%d", mlt_properties_count( codecs ) );
				mlt_properties_set( codecs, key, codec->name );
			}
		s = mlt_properties_serialise_yaml( doc );
		fprintf( stdout, "%s", s );
		free( s );
		mlt_properties_close( doc );
		error = 1;
	}

	// Check that we're not already running
	if ( !error && !mlt_properties_get_int( properties, "running" ) )
	{
		// Allocate a thread
		pthread_t *thread = calloc( 1, sizeof( pthread_t ) );

		mlt_event_block( mlt_properties_get_data( properties, "property-changed event", NULL ) );

		// Assign the thread to properties
		mlt_properties_set_data( properties, "thread", thread, sizeof( pthread_t ), free, NULL );

		// Create the thread
		pthread_create( thread, NULL, consumer_thread, consumer );

		// Set the running state
		mlt_properties_set_int( properties, "running", 1 );
	}
	return error;
}

/** Stop the consumer.
*/

static int consumer_stop( mlt_consumer consumer )
{
	// Get the properties
	mlt_properties properties = MLT_CONSUMER_PROPERTIES( consumer );
	pthread_t *thread = mlt_properties_get_data( properties, "thread", NULL );

	// Check that we're running
	if ( thread )
	{
		// Stop the thread
		mlt_properties_set_int( properties, "running", 0 );

		// Wait for termination
		pthread_join( *thread, NULL );

		mlt_properties_set_data( properties, "thread", NULL, 0, NULL, NULL );
		mlt_event_unblock( mlt_properties_get_data( properties, "property-changed event", NULL ) );
	}

	return 0;
}

/** Determine if the consumer is stopped.
*/

static int consumer_is_stopped( mlt_consumer consumer )
{
	// Get the properties
	mlt_properties properties = MLT_CONSUMER_PROPERTIES( consumer );
	return !mlt_properties_get_int( properties, "running" );
}

/** Process properties as AVOptions and apply to AV context obj
*/

static void apply_properties( void *obj, mlt_properties properties, int flags )
{
	int i;
	int count = mlt_properties_count( properties );

	for ( i = 0; i < count; i++ )
	{
		const char *opt_name = mlt_properties_get_name( properties, i );
		int search_flags = AV_OPT_SEARCH_CHILDREN;
		const AVOption *opt = av_opt_find( obj, opt_name, NULL, flags, search_flags );

		// If option not found, see if it was prefixed with a or v (-vb)
		if ( !opt && (
			( opt_name[0] == 'v' && ( flags & AV_OPT_FLAG_VIDEO_PARAM ) ) ||
			( opt_name[0] == 'a' && ( flags & AV_OPT_FLAG_AUDIO_PARAM ) ) ) )
			opt = av_opt_find( obj, ++opt_name, NULL, flags, search_flags );
		// Apply option if found
		if ( opt &&  strcmp( opt_name, "channel_layout" ) )
			av_opt_set( obj, opt_name, mlt_properties_get_value( properties, i), search_flags );
	}
}

static enum AVPixelFormat pick_pix_fmt( mlt_image_format img_fmt )
{
	switch ( img_fmt )
	{
	case mlt_image_rgb24:
		return AV_PIX_FMT_RGB24;
	case mlt_image_rgb24a:
		return AV_PIX_FMT_RGBA;
	case mlt_image_yuv420p:
		return AV_PIX_FMT_YUV420P;
	case mlt_image_yuv422p16:
		return AV_PIX_FMT_YUV422P16LE;
	default:
		return AV_PIX_FMT_YUYV422;
	}
}

static int get_mlt_audio_format( int av_sample_fmt )
{
	switch ( av_sample_fmt )
	{
	case AV_SAMPLE_FMT_U8:
		return mlt_audio_u8;
	case AV_SAMPLE_FMT_S32:
		return mlt_audio_s32le;
	case AV_SAMPLE_FMT_FLT:
		return mlt_audio_f32le;
	case AV_SAMPLE_FMT_U8P:
		return mlt_audio_u8;
	case AV_SAMPLE_FMT_S32P:
		return mlt_audio_s32le;
	case AV_SAMPLE_FMT_FLTP:
		return mlt_audio_f32le;
	default:
		return mlt_audio_s16;
	}
}

static int pick_sample_fmt( mlt_properties properties, AVCodec *codec )
{
	int sample_fmt = AV_SAMPLE_FMT_S16;
	const char *format = mlt_properties_get( properties, "mlt_audio_format" );
	const int *p = codec->sample_fmts;

	// get default av_sample_fmt from mlt_audio_format
	if ( format )
	{
		if ( !strcmp( format, "s32le" ) )
			sample_fmt = AV_SAMPLE_FMT_S32;
		else if ( !strcmp( format, "f32le" ) )
			sample_fmt = AV_SAMPLE_FMT_FLT;
		else if ( !strcmp( format, "u8" ) )
			sample_fmt = AV_SAMPLE_FMT_U8;
		else if ( !strcmp( format, "s32" ) )
			sample_fmt = AV_SAMPLE_FMT_S32P;
		else if ( !strcmp( format, "float" ) )
			sample_fmt = AV_SAMPLE_FMT_FLTP;
	}
	// check if codec supports our mlt_audio_format
	for ( ; *p != -1; p++ )
	{
		if ( *p == sample_fmt )
			return sample_fmt;
	}
	// no match - pick first one we support
	for ( p = codec->sample_fmts; *p != -1; p++ )
	{
		switch (*p)
		{
		case AV_SAMPLE_FMT_U8:
		case AV_SAMPLE_FMT_S16:
		case AV_SAMPLE_FMT_S32:
		case AV_SAMPLE_FMT_FLT:
		case AV_SAMPLE_FMT_U8P:
		case AV_SAMPLE_FMT_S16P:
		case AV_SAMPLE_FMT_S32P:
		case AV_SAMPLE_FMT_FLTP:
			return *p;
		default:
			break;
		}
	}
	mlt_log_error( properties, "audio codec sample_fmt not compatible" );

	return AV_SAMPLE_FMT_NONE;
}

/** Add a video output stream 
*/

static AVStream *add_video_stream( mlt_consumer consumer, AVFormatContext *oc, AVCodec *codec )
{
 	// Get the properties
	mlt_properties properties = MLT_CONSUMER_PROPERTIES( consumer );

	// Create a new stream
	AVStream *st = avformat_new_stream( oc, codec );

	if ( st != NULL ) 
	{
		char *pix_fmt = mlt_properties_get( properties, "pix_fmt" );
		AVCodecContext *c = st->codec;

		// Establish defaults from AVOptions
		avcodec_get_context_defaults3( c, codec );

		c->codec_id = codec->id;
		c->codec_type = AVMEDIA_TYPE_VIDEO;
		
		// Setup multi-threading
		int thread_count = mlt_properties_get_int( properties, "threads" );
		if ( thread_count == 0 && getenv( "MLT_AVFORMAT_THREADS" ) )
			thread_count = atoi( getenv( "MLT_AVFORMAT_THREADS" ) );
		if ( thread_count >= 0 )
			c->thread_count = thread_count;
		// Set options controlled by MLT
		c->width = mlt_properties_get_int( properties, "width" );
		c->height = mlt_properties_get_int( properties, "height" );
		c->time_base.num = mlt_properties_get_int( properties, "frame_rate_den" );
		c->time_base.den = mlt_properties_get_int( properties, "frame_rate_num" );
		st->time_base = c->time_base;
		st->avg_frame_rate = av_inv_q( c->time_base );
#if LIBAVCODEC_VERSION_INT >= AV_VERSION_INT(56, 5, 0)
		c->framerate = av_inv_q( c->time_base );
#endif

		// Default to the codec's first pix_fmt if possible.
		c->pix_fmt = pix_fmt ? av_get_pix_fmt( pix_fmt ) : codec ?
			( codec->pix_fmts ? codec->pix_fmts[0] : AV_PIX_FMT_YUV422P ): AV_PIX_FMT_YUV420P;

	}
	else
	{
		mlt_log_error( MLT_CONSUMER_SERVICE( consumer ), "Could not allocate a stream for video\n" );
	}
 
	return st;
}

static AVFrame *alloc_picture( int pix_fmt, int width, int height )
{
	// Allocate a frame
	AVFrame *picture = av_frame_alloc();

	if ( picture )
	{
		int size = av_image_alloc(picture->data, picture->linesize, width, height, pix_fmt, IMAGE_ALIGN);
		if (size > 0) {
			picture->format = pix_fmt;
			picture->width = width;
			picture->height = height;
		} else {
			av_free( picture );
			picture = NULL;
		}
	}
	else
	{
		// Something failed - clean up what we can
	 	av_free( picture );
	 	picture = NULL;
	}

	return picture;
}

static int open_video( mlt_properties properties, AVFormatContext *oc, AVStream *st, const char *codec_name )
{
	// Get the codec
	AVCodecContext *video_enc = st->codec;

	// find the video encoder
	AVCodec *codec;
	if ( codec_name )
		codec = avcodec_find_encoder_by_name( codec_name );
	else
		codec = avcodec_find_encoder( video_enc->codec_id );

	if( codec && codec->pix_fmts )
	{
		const enum AVPixelFormat *p = codec->pix_fmts;
		for( ; *p!=-1; p++ )
		{
			if( *p == video_enc->pix_fmt )
				break;
		}
		if( *p == -1 )
			video_enc->pix_fmt = codec->pix_fmts[ 0 ];
	}

	int result = codec && avcodec_open2( video_enc, codec, NULL ) >= 0;
	
	return result;
}

void close_video(AVFormatContext *oc, AVStream *st)
{
	if ( st && st->codec )
	{
		av_freep( &st->codec->stats_in );
		avcodec_close(st->codec);
	}
}

typedef struct encode_ctx_desc
{
	mlt_consumer consumer;
	int audio_outbuf_size;
	int audio_input_frame_size;
	uint8_t audio_outbuf[AUDIO_BUFFER_SIZE], audio_buf_1[AUDIO_ENCODE_BUFFER_SIZE], audio_buf_2[AUDIO_ENCODE_BUFFER_SIZE];

	int channels;
	int total_channels;
	int frequency;
	int sample_bytes;


	AVFormatContext *oc;
	AVStream *video_st;
	AVStream *audio_st[ MAX_AUDIO_STREAMS ];
	int64_t sample_count[ MAX_AUDIO_STREAMS ];

	// Used to store and override codec ids
	int video_codec_id;
	int audio_codec_id;

	int error_count;
	int frame_count;

	double audio_pts;
	double video_pts;

	int terminate_on_pause;
	int terminated;
	mlt_properties properties;
	mlt_properties frame_meta_properties;

	AVFrame *audio_avframe;
} encode_ctx_t;

/** The main thread - the argument is simply the consumer.
*/

static void *consumer_thread( void *arg )
{
	int i;

	// Encoding content
	encode_ctx_t* enc_ctx = mlt_pool_alloc(sizeof(encode_ctx_t));
	memset(enc_ctx, 0, sizeof(encode_ctx_t));

	// Map the argument to the object
	mlt_consumer consumer = enc_ctx->consumer = arg;

	// Get the properties
	mlt_properties properties = enc_ctx->properties = MLT_CONSUMER_PROPERTIES( consumer );

	// Get the terminate on pause property
	enc_ctx->terminate_on_pause = mlt_properties_get_int( enc_ctx->properties, "terminate_on_pause" );

	// Determine if feed is slow (for realtime stuff)
	int real_time_output = mlt_properties_get_int( properties, "real_time" );

	// Time structures
	struct timeval ante;

	// Get the frame rate
	double fps = mlt_properties_get_double( properties, "fps" );

	// Get width and height
	int width = mlt_properties_get_int( properties, "width" );
	int height = mlt_properties_get_int( properties, "height" );
	int img_width = width;
	int img_height = height;

	// AVFormat video buffer and frame count
	int video_outbuf_size = VIDEO_BUFFER_SIZE;
	uint8_t *video_outbuf = av_malloc( video_outbuf_size );

	// Used for the frame properties
	mlt_frame frame = NULL;
	mlt_properties frame_properties = NULL;

	// Get the queues
	mlt_deque queue = mlt_properties_get_data( properties, "frame_queue", NULL );

	// For receiving images from an mlt_frame
	uint8_t *image;
	mlt_image_format img_fmt = mlt_image_yuv422;

	// Need two av pictures for converting
	AVFrame *converted_avframe = NULL;
	AVFrame *avframe = NULL;

	// For receiving audio samples back from the fifo
	int count = 0;

	// Frames dispatched
	long int frames = 0;
	long int total_time = 0;

	// Determine the format
	AVOutputFormat *fmt = NULL;
	const char *filename = mlt_properties_get( properties, "target" );
	char *format = mlt_properties_get( properties, "f" );
	char *vcodec = mlt_properties_get( properties, "vcodec" );
	char *acodec = mlt_properties_get( properties, "acodec" );
	AVCodec *audio_codec = NULL;
	AVCodec *video_codec = NULL;


	// Misc
	char key[27];
	enc_ctx->frame_meta_properties = mlt_properties_new();
	int header_written = 0;

	// Check for user selected format first
	if ( format != NULL )
		fmt = av_guess_format( format, NULL, NULL );

	// Otherwise check on the filename
	if ( fmt == NULL && filename != NULL )
		fmt = av_guess_format( NULL, filename, NULL );

	enc_ctx->oc = avformat_alloc_context( );
	enc_ctx->oc->oformat = fmt;
	snprintf( enc_ctx->oc->filename, sizeof(enc_ctx->oc->filename), "%s", filename );

	// Get the codec ids selected
	enc_ctx->audio_codec_id = fmt->audio_codec;
	enc_ctx->video_codec_id = fmt->video_codec;

	// Check for audio codec overrides
	if ( ( acodec && strcmp( acodec, "none" ) == 0 ) || mlt_properties_get_int( properties, "an" ) )
		enc_ctx->audio_codec_id = AV_CODEC_ID_NONE;

	// Check for video codec overrides
	if ( ( vcodec && strcmp( vcodec, "none" ) == 0 ) || mlt_properties_get_int( properties, "vn" ) )
		enc_ctx->video_codec_id = AV_CODEC_ID_NONE;
	else if ( vcodec )
	{
		video_codec = avcodec_find_encoder_by_name( vcodec );
		if ( video_codec )
		{
			enc_ctx->video_codec_id = video_codec->id;
		}
	}

	// Add audio and video streams
	if ( enc_ctx->video_codec_id != AV_CODEC_ID_NONE )
	{
		if ( ( enc_ctx->video_st = add_video_stream( consumer, enc_ctx->oc, video_codec ) ) )
		{
		}
	}

	// Set the parameters (even though we have none...)
	{

		if ( enc_ctx->video_st && !open_video( properties, enc_ctx->oc, enc_ctx->video_st, vcodec? vcodec : NULL ) )
			enc_ctx->video_st = NULL;
		// Open the output file, if needed
		else if ( !( fmt->flags & AVFMT_NOFILE ) )
		{
			if ( avio_open( &enc_ctx->oc->pb, filename, AVIO_FLAG_WRITE ) < 0 ) //ok storm
			{
			}
		}

	}


	// Allocate picture
	enum AVPixelFormat pix_fmt;
	if ( enc_ctx->video_st ) {
		pix_fmt = enc_ctx->video_st->codec->pix_fmt == AV_PIX_FMT_VAAPI ?
				   AV_PIX_FMT_NV12 : enc_ctx->video_st->codec->pix_fmt;
		converted_avframe = alloc_picture( pix_fmt, width, height );
		if ( !converted_avframe ) {
			mlt_log_error( MLT_CONSUMER_SERVICE( consumer ), "failed to allocate video AVFrame\n" );
			mlt_events_fire( properties, "consumer-fatal-error", NULL );
			goto on_fatal_error;
		}
	}

	// Get the starting time (can ignore the times above)
	gettimeofday( &ante, NULL );

	// Loop while running
	while( mlt_properties_get_int( properties, "running" ) &&
	       ( !enc_ctx->terminated || ( enc_ctx->video_st && mlt_deque_count( queue ) ) ) )
	{
		if ( !frame )
			frame = mlt_consumer_rt_frame( consumer );

		// Check that we have a frame to work with
		if ( frame != NULL )
		{
			// Default audio args
			frame_properties = MLT_FRAME_PROPERTIES( frame );

			// Write the stream header.
			if ( !header_written )
			{

				if ( avformat_write_header( enc_ctx->oc, NULL ) < 0 )
				{
					mlt_log_error( MLT_CONSUMER_SERVICE( consumer ), "Could not write header '%s'\n", filename );
					mlt_events_fire( properties, "consumer-fatal-error", NULL );
					goto on_fatal_error;
				}

				header_written = 1;
			}

			// Increment frames dispatched
			frames ++;

			// Check for the terminated condition
			enc_ctx->terminated = enc_ctx->terminate_on_pause && mlt_properties_get_double( frame_properties, "_speed" ) == 0.0;


			// Encode the image
			if ( !enc_ctx->terminated && enc_ctx->video_st )
				mlt_deque_push_back( queue, frame );
			else
				mlt_frame_close( frame );
			frame = NULL;
		}

		// While we have stuff to process, process...
		while ( 1 )
		{
			if ( enc_ctx->video_st )
			{
				// Write video
				if ( mlt_deque_count( queue ) )
				{
					int ret = 0;
					AVCodecContext *c = enc_ctx->video_st->codec;

					frame = mlt_deque_pop_front( queue );
					frame_properties = MLT_FRAME_PROPERTIES( frame );

					if ( mlt_properties_get_int( frame_properties, "rendered" ) ) //ok storm
					{
#if 1
						AVFrame video_avframe;
						mlt_frame_get_image( frame, &image, &img_fmt, &img_width, &img_height, 0 );

						mlt_image_format_planes( img_fmt, width, height, image, video_avframe.data, video_avframe.linesize );

						// Do the colour space conversion
						int flags = mlt_default_sws_flags;
						struct SwsContext *context = sws_getContext( width, height, pick_pix_fmt( img_fmt ),
							width, height, pix_fmt, flags, NULL, NULL, NULL);
						sws_scale( context, (const uint8_t* const*) video_avframe.data, video_avframe.linesize, 0, height,
							converted_avframe->data, converted_avframe->linesize);
						sws_freeContext( context );

						mlt_events_fire( properties, "consumer-frame-show", frame, NULL );
#endif
						// Apply the alpha if applicable
						if ( !mlt_properties_get( properties, "mlt_image_format" ) ||
						     strcmp( mlt_properties_get( properties, "mlt_image_format" ), "rgb24a" ) )

						{ //ok storm
							avframe = converted_avframe;
						}
					}

					{
						AVPacket pkt;
						av_init_packet( &pkt );
						if ( c->codec->id == AV_CODEC_ID_RAWVIDEO ) {
							pkt.data = NULL;
							pkt.size = 0;
						} else {
							pkt.data = video_outbuf;
							pkt.size = video_outbuf_size;
						}

						avframe->pts = enc_ctx->frame_count;

	 					// Encode the image
						ret = avcodec_send_frame( c, avframe );
						if ( ret < 0 ) {
							pkt.size = ret;
						} else {
receive_video_packet:
							ret = avcodec_receive_packet( c, &pkt );
							if ( ret == AVERROR(EAGAIN) || ret == AVERROR_EOF )
								pkt.size = ret = 0;
							else if ( ret < 0 )
								pkt.size = ret;
						}

	 					// If zero size, it means the image was buffered
						if ( pkt.size > 0 )
						{
                            mlt_log_debug( MLT_CONSUMER_SERVICE( consumer ), "encoder -> type:video before scale"
                                    "pkt_pts:%d pkt_dts:%d pkt_dts_time:%d/%d \n",
                                    pkt.pts, 
                                    pkt.dts, c->time_base.num, c->time_base.den
                                    );

							if ( pkt.pts != AV_NOPTS_VALUE )
								pkt.pts = av_rescale_q( pkt.pts, c->time_base, enc_ctx->video_st->time_base );
							if ( pkt.dts != AV_NOPTS_VALUE )
								pkt.dts = av_rescale_q( pkt.dts, c->time_base, enc_ctx->video_st->time_base );
							pkt.stream_index = enc_ctx->video_st->index;
                            mlt_log_debug( MLT_CONSUMER_SERVICE( consumer ), "encoder -> type:video after scale"
                                    "pkt_pts:%d pkt_dts:%d pkt_dts_time:%d/%d \n",
                                    pkt.pts, 
                                    pkt.dts, enc_ctx->video_st->time_base.num, enc_ctx->video_st->time_base.den
                                    );

							// write the compressed frame in the media file
							ret = av_interleaved_write_frame(enc_ctx->oc, &pkt);
							mlt_log_debug( MLT_CONSUMER_SERVICE( consumer ), " frame_size %d\n", c->frame_size );
							

							enc_ctx->error_count = 0;

#if LIBAVCODEC_VERSION_INT >= ((57<<16)+(37<<8)+0)
							if ( !ret )
								goto receive_video_packet;
#endif
						}
						else if ( pkt.size < 0 )
						{
							mlt_log_warning( MLT_CONSUMER_SERVICE(consumer), "error with video encode: %d (frame %d)\n", pkt.size, enc_ctx->frame_count );
							if ( ++enc_ctx->error_count > 2 )
								goto on_fatal_error;
							ret = 0;
						}
 					}
					enc_ctx->frame_count++;
					enc_ctx->video_pts = (double) enc_ctx->frame_count * av_q2d( enc_ctx->video_st->codec->time_base );
					if ( ret )
					{
						mlt_log_fatal( MLT_CONSUMER_SERVICE(consumer), "error writing video frame: %d\n", ret );
						mlt_events_fire( properties, "consumer-fatal-error", NULL );
						goto on_fatal_error;
					}
					mlt_frame_close( frame );
					frame = NULL;
				}
				else
				{
					break;
				}
			}
		}

	}

	// Flush the encoder buffers
	if ( real_time_output <= 0 )
	{
		// Flush video
        if ( enc_ctx->video_st ) for (;;)
		{
			AVCodecContext *c = enc_ctx->video_st->codec;
			AVPacket pkt;
			av_init_packet( &pkt );
			if ( c->codec->id == AV_CODEC_ID_RAWVIDEO ) {
				pkt.data = NULL;
				pkt.size = 0;
			} else {
				pkt.data = video_outbuf;
				pkt.size = video_outbuf_size;
			}

			// Encode the image
			int ret;
			while ( (ret = avcodec_receive_packet( c, &pkt )) == AVERROR(EAGAIN) ) {
				ret = avcodec_send_frame( c, NULL );
				if ( ret < 0 ) {
					mlt_log_warning( MLT_CONSUMER_SERVICE(consumer), "error with video encode: %d\n", ret );
					break;
				}
			}
			mlt_log_debug( MLT_CONSUMER_SERVICE( consumer ), "flushing video size %d\n", pkt.size );
			if ( pkt.size < 0 )
				break;
			if ( !pkt.size )
				break;

            mlt_log_debug( MLT_CONSUMER_SERVICE( consumer ), "encoder -> type:video before scale"
                    "pkt_pts:%d pkt_dts:%d pkt_dts_time:%d/%d \n",
                    pkt.pts, 
                    pkt.dts, c->time_base.num, c->time_base.den
                    );
			if ( pkt.pts != AV_NOPTS_VALUE )
				pkt.pts = av_rescale_q( pkt.pts, c->time_base, enc_ctx->video_st->time_base );
			if ( pkt.dts != AV_NOPTS_VALUE )
				pkt.dts = av_rescale_q( pkt.dts, c->time_base, enc_ctx->video_st->time_base );
			pkt.stream_index = enc_ctx->video_st->index;
            mlt_log_debug( MLT_CONSUMER_SERVICE( consumer ), "encoder -> type:video after scale"
                    "pkt_pts:%d pkt_dts:%d pkt_dts_time:%d/%d \n",
                    pkt.pts, 
                    pkt.dts, enc_ctx->video_st->time_base.num, enc_ctx->video_st->time_base.den
                    );

			// write the compressed frame in the media file
			if ( av_interleaved_write_frame( enc_ctx->oc, &pkt ) != 0 )
			{
				mlt_log_fatal( MLT_CONSUMER_SERVICE(consumer), "error writing flushed video frame\n" );
				mlt_events_fire( properties, "consumer-fatal-error", NULL );
				goto on_fatal_error;
			}
		}
	}

on_fatal_error:

	if ( frame )
		mlt_frame_close( frame );

	// Write the trailer, if any
	if ( frames )
		av_write_trailer( enc_ctx->oc );

	// Clean up input and output frames
	if ( converted_avframe )
		av_free( converted_avframe->data[0] );
	av_free( converted_avframe );
#if defined(AVFILTER) && LIBAVUTIL_VERSION_MAJOR >= 56
	if (enc_ctx->video_st && enc_ctx->video_st->codec && AV_PIX_FMT_VAAPI == enc_ctx->video_st->codec->pix_fmt)
		av_frame_free(&avframe);
#endif
	av_free( video_outbuf );
	av_free( enc_ctx->audio_avframe );

	// close each codec
	if ( enc_ctx->video_st )
		close_video(enc_ctx->oc, enc_ctx->video_st);

	// Free the streams
	for ( i = 0; i < enc_ctx->oc->nb_streams; i++ )
		av_freep( &enc_ctx->oc->streams[i] );

	// Close the output file
	if ( !( fmt->flags & AVFMT_NOFILE ) &&
		!mlt_properties_get_int( properties, "redirect" ) )
	{
		if ( enc_ctx->oc->pb  ) avio_close( enc_ctx->oc->pb );
	}

	// Free the stream
	av_free( enc_ctx->oc );

	// Just in case we terminated on pause
	mlt_consumer_stopped( consumer );
	mlt_properties_close( enc_ctx->frame_meta_properties );

	while ( ( frame = mlt_deque_pop_back( queue ) ) )
		mlt_frame_close( frame );

	mlt_pool_release( enc_ctx );

	return NULL;
}
/** Close the consumer.
*/

static void consumer_close( mlt_consumer consumer )
{
	// Stop the consumer
	mlt_consumer_stop( consumer );

	// Close the parent
	mlt_consumer_close( consumer );

	// Free the memory
	free( consumer );
}
